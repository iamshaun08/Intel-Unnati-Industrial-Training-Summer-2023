# -*- coding: utf-8 -*-
"""Go SOLO_Smart Mobile Phone Price Prediction using Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CN1AW2dC0OzZWLXf_zPOO90GMroc-8Ux
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.decomposition import PCA

"""**Data Description and EDA**"""

train = pd.read_csv("/content/drive/MyDrive/Intel/train.csv")
test = pd.read_csv("/content/drive/MyDrive/Intel/test.csv").drop('id', axis=1)

#attributes
train.columns

#dimension of the dataset
train.shape

#description of the attributes
train.iloc[:,:11].describe()

train.iloc[:,11:].describe()

#datatypes of attributes
train.dtypes

#checking for null values
pd.isnull(train).sum()

#correlation between attributes
sns.heatmap(train.corr(), cmap="GnBu")

# checking if the dataset is balanced
print("Number of pricing options:", len(train['price_range'].unique()))
prices = ['Cheap', 'Budget', 'Expensive', 'Premium']
print("Pricing options:", prices)

plt.hist(train['price_range'])
plt.xlabel(prices)
plt.title('Counts of price classification')
#Dataset is balanced

#splitting the data
X = train.drop('price_range', axis = 1)
y = train['price_range'].values.reshape(-1,1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=56)

"""**Model Building**"""

#Raw model without any dimensionality reduction techniques
raw_model = LogisticRegression(multi_class = 'multinomial', solver = 'sag',  max_iter = 10000)
raw_model.fit(X_train, y_train.ravel())

y_pred_raw = raw_model.predict(X_test)

#Analysing the raw model
raw_acc = accuracy_score(y_test, y_pred_raw)*100
print("Raw accuracy:", raw_acc)

#Using Principal Component Analysis


#FeatureScaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

pca = PCA(n_components=14)

X_train_pca = pca.fit_transform(X_train, y_train.ravel())
X_test_pca = pca.transform(X_test)

pca_model = LogisticRegression(multi_class = 'multinomial', solver = 'sag',  max_iter = 10000)
pca_model.fit(X_train_pca, y_train.ravel())

y_pred_pca = pca_model.predict(X_test_pca)

#Analysing the PCA model
pca_acc = accuracy_score(y_test, y_pred_pca)*100
print("PCA accuracy:", pca_acc)

#Using Linear Discriminant Analysis

LDA = LinearDiscriminantAnalysis(n_components=1)

X_train_lda = LDA.fit_transform(X_train, y_train.ravel())
X_test_lda = LDA.transform(X_test)

lda_model = LogisticRegression(multi_class = 'multinomial', solver = 'sag',  max_iter = 10000)
lda_model.fit(X_train_lda, y_train.ravel())

y_pred_lda = lda_model.predict(X_test_lda)

lda_acc = accuracy_score(y_test, y_pred_lda)*100
print("LDA accuracy:", lda_acc)

"""**Conclusion**"""

models = ['raw_model', 'pca_model', 'lda_model']
acc = [raw_acc, pca_acc, lda_acc]

plt.bar(models, acc)
plt.title('Model Comparision')
plt.xlabel('Models')
plt.ylabel('Accuracy')

"""So, the dimensionality reduction techniques like PCA and LDA can highly imporve the model"""

#Testing with LDA

n = int(input("Enter test instance to be tested (0 - 999): "))

print("\nTest instance")
print(test.iloc[n])

X = sc.transform(test)
X = LDA.transform(X)

print("\nPredicted range:", prices[lda_model.predict(X)[n]])
